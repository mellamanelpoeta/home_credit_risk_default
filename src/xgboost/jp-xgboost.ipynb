{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7823c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     classification_report, confusion_matrix, roc_auc_score, \n\u001b[1;32m      9\u001b[0m     roc_curve, precision_recall_curve, average_precision_score\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/core.py:269\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/core.py:222\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    221\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(ver: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACIÓN\n",
    "# =============================================================================\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Hiperparámetros XGBoost - Modelo 1\n",
    "N_ESTIMATORS = 100\n",
    "MAX_DEPTH = 6\n",
    "LEARNING_RATE = 0.1\n",
    "MIN_CHILD_WEIGHT = 5\n",
    "SUBSAMPLE = 0.8\n",
    "COLSAMPLE_BYTREE = 0.8\n",
    "\n",
    "# Directorio de salida\n",
    "OUTPUT_DIR = \"../../data/xgboost-output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODELO XGBOOST - HOME CREDIT DEFAULT RISK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTipo de problema: CLASIFICACIÓN BINARIA (0 = Pago, 1 = Default)\")\n",
    "print(f\"Algoritmo: Extreme Gradient Boosting (XGBoost)\")\n",
    "print(f\"Directorio de salida: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f154984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. CARGA Y VERIFICACIÓN DE DATOS\n",
    "# =============================================================================\n",
    "print(\"\\n[1/15] Cargando y verificando datos...\")\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/variables.csv\")\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape}\")\n",
    "print(f\"Usuarios: {len(df):,}\")\n",
    "print(f\"Variables: {len(df.columns)}\")\n",
    "print(f\"Tasa de default: {df['TARGET'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4115b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. PREPARACIÓN DE DATOS\n",
    "# =============================================================================\n",
    "print(\"\\n[2/15] Preparando datos...\")\n",
    "\n",
    "X = df.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "print(f\"Variables predictoras: {X.shape[1]}\")\n",
    "print(f\"Variable objetivo: {y.name}\")\n",
    "\n",
    "numeric_vars = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_vars = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Variables numericas: {len(numeric_vars)}\")\n",
    "print(f\"Variables categoricas: {len(categorical_vars)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b411cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. MANEJO DE VALORES FALTANTES\n",
    "# =============================================================================\n",
    "print(\"\\n[3/15] Analizando valores faltantes...\")\n",
    "\n",
    "missing_pct = (X.isnull().sum() / len(X) * 100).sort_values(ascending=False)\n",
    "missing_vars = missing_pct[missing_pct > 0]\n",
    "\n",
    "if len(missing_vars) > 0:\n",
    "    print(f\"Variables con valores faltantes: {len(missing_vars)}\")\n",
    "    print(missing_vars.head(10))\n",
    "    \n",
    "    print(\"\\nImputando valores faltantes...\")\n",
    "    for col in numeric_vars:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    for col in categorical_vars:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "    \n",
    "    print(\"Valores faltantes imputados\")\n",
    "else:\n",
    "    print(\"No hay valores faltantes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fde402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. CODIFICACIÓN DE VARIABLES CATEGÓRICAS\n",
    "# =============================================================================\n",
    "print(\"\\n[4/15] Codificando variables categoricas...\")\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "if len(categorical_vars) > 0:\n",
    "    for col in categorical_vars:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    print(f\"{len(categorical_vars)} variables codificadas\")\n",
    "    print(f\"Categorias: {categorical_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. DIVISIÓN TRAIN/TEST\n",
    "# =============================================================================\n",
    "print(\"\\n[5/15] Dividiendo datos en Train/Test...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]:,} usuarios ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:  {X_test.shape[0]:,} usuarios ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nDistribucion TARGET en Train:\")\n",
    "print(f\"  Clase 0 (Pago): {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (Default): {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. NOTA SOBRE NORMALIZACIÓN\n",
    "# =============================================================================\n",
    "print(\"\\n[6/15] Nota sobre normalizacion...\")\n",
    "\n",
    "# XGBoost NO requiere normalización ya que es un modelo basado en árboles\n",
    "# Los árboles de decisión son invariantes a transformaciones monótonas de las features\n",
    "# Usamos los datos sin escalar para mejor interpretabilidad\n",
    "\n",
    "print(\"XGBoost no requiere normalizacion de datos\")\n",
    "print(\"Los arboles de decision son invariantes a escalas de las variables\")\n",
    "print(\"Se usaran los datos originales (sin escalar)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7912b",
   "metadata": {},
   "source": [
    "# XGBoost 1 - Modelo con todas las variables (39 features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. ENTRENAMIENTO DEL MODELO XGBOOST 1\n",
    "# =============================================================================\n",
    "print(\"\\n[7/15] Entrenando XGBoost...\")\n",
    "\n",
    "# Calcular scale_pos_weight para manejar desbalance de clases\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale_pos_weight (ratio negativo/positivo): {scale_pos_weight:.2f}\")\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    min_child_weight=MIN_CHILD_WEIGHT,\n",
    "    subsample=SUBSAMPLE,\n",
    "    colsample_bytree=COLSAMPLE_BYTREE,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModelo entrenado exitosamente\")\n",
    "print(f\"Numero de arboles: {model.n_estimators}\")\n",
    "print(f\"Profundidad maxima: {model.max_depth}\")\n",
    "print(f\"Learning rate: {model.learning_rate}\")\n",
    "print(f\"Min child weight: {model.min_child_weight}\")\n",
    "print(f\"Subsample: {model.subsample}\")\n",
    "print(f\"Colsample bytree: {model.colsample_bytree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. VALIDACIÓN CRUZADA\n",
    "# =============================================================================\n",
    "print(f\"\\n[8/15] Validacion Cruzada ({CV_FOLDS}-fold en Train)...\")\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    model, X_train, y_train, \n",
    "    cv=CV_FOLDS, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"ROC-AUC por fold: {cv_scores}\")\n",
    "print(f\"Media: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 9. PREDICCIONES\n",
    "# =============================================================================\n",
    "print(\"\\n[9/15] Generando predicciones...\")\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predicciones generadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 10. EVALUACIÓN EN TRAIN\n",
    "# =============================================================================\n",
    "print(\"\\n[10/15] Evaluando modelo en TRAIN SET...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "train_ap = average_precision_score(y_train, y_train_proba)\n",
    "\n",
    "print(f\"\\nMetricas Globales:\")\n",
    "print(f\"ROC-AUC Score: {train_auc:.4f}\")\n",
    "print(f\"Average Precision: {train_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, y_train_pred, \n",
    "                          target_names=['Pago (0)', 'Default (1)']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nInterpretacion:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {cm_train[0,0]:,} - Predijo 'Pago' y si pago\")\n",
    "print(f\"  Falsos Positivos (FP): {cm_train[0,1]:,} - Predijo 'Default' pero pago\")\n",
    "print(f\"  Falsos Negativos (FN): {cm_train[1,0]:,} - Predijo 'Pago' pero hizo default [CRITICO]\")\n",
    "print(f\"  Verdaderos Positivos (TP): {cm_train[1,1]:,} - Predijo 'Default' y si hizo default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 11. EVALUACIÓN EN TEST\n",
    "# =============================================================================\n",
    "print(\"\\n[11/15] Evaluando modelo en TEST SET (metricas definitivas)...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "test_ap = average_precision_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\nMetricas Globales:\")\n",
    "print(f\"ROC-AUC Score: {test_auc:.4f}\")\n",
    "print(f\"Average Precision: {test_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['Pago (0)', 'Default (1)']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nInterpretacion:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {cm_test[0,0]:,} - Predijo 'Pago' y si pago\")\n",
    "print(f\"  Falsos Positivos (FP): {cm_test[0,1]:,} - Predijo 'Default' pero pago\")\n",
    "print(f\"  Falsos Negativos (FN): {cm_test[1,0]:,} - Predijo 'Pago' pero hizo default [CRITICO]\")\n",
    "print(f\"  Verdaderos Positivos (TP): {cm_test[1,1]:,} - Predijo 'Default' y si hizo default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 12. COMPARACIÓN TRAIN VS TEST\n",
    "# =============================================================================\n",
    "print(\"\\n[12/15] Comparando TRAIN vs TEST (analisis de overfitting)...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Metrica':<25} {'Train':<12} {'Test':<12} {'Diferencia':<12}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'ROC-AUC':<25} {train_auc:<12.4f} {test_auc:<12.4f} {abs(train_auc-test_auc):<12.4f}\")\n",
    "print(f\"{'Average Precision':<25} {train_ap:<12.4f} {test_ap:<12.4f} {abs(train_ap-test_ap):<12.4f}\")\n",
    "\n",
    "diff_auc = abs(train_auc - test_auc)\n",
    "if diff_auc < 0.02:\n",
    "    print(\"\\nExcelente generalizacion (diferencia < 2%)\")\n",
    "elif diff_auc < 0.05:\n",
    "    print(\"\\nBuena generalizacion (diferencia < 5%)\")\n",
    "elif diff_auc < 0.10:\n",
    "    print(\"\\nPosible ligero overfitting (diferencia 5-10%)\")\n",
    "else:\n",
    "    print(\"\\nOverfitting detectado (diferencia > 10%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 13. IMPORTANCIA DE VARIABLES\n",
    "# =============================================================================\n",
    "print(\"\\n[13/15] Calculando importancia de variables...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# XGBoost usa importancia basada en gain (ganancia promedio en splits)\n",
    "# También puede usar weight (número de veces que se usa) o cover (muestras cubiertas)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importancia': model.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 variables mas importantes para predecir default:\\n\")\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nInterpretacion de importancia (Gain):\")\n",
    "print(\"  - Problema de CLASIFICACIÓN BINARIA: predecir 0 (Pago) o 1 (Default)\")\n",
    "print(\"  - Gain mide la mejora promedio en la función objetivo al usar la variable\")\n",
    "print(\"  - Valores mas altos = mayor capacidad para mejorar las predicciones\")\n",
    "print(\"  - Basado en la ganancia promedio en todos los árboles del ensemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1408657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 14. VISUALIZACIONES\n",
    "# =============================================================================\n",
    "print(\"\\n[14/15] Generando visualizaciones...\")\n",
    "\n",
    "# Calcular deciles\n",
    "test_results = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_proba': y_test_proba\n",
    "})\n",
    "test_results['decil'] = pd.qcut(test_results['y_proba'], q=10, labels=False, duplicates='drop') + 1\n",
    "\n",
    "# Calcular TPR por decil\n",
    "decil_stats = test_results.groupby('decil').agg({\n",
    "    'y_true': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "decil_stats.columns = ['decil', 'positivos', 'total', 'tpr']\n",
    "decil_stats = decil_stats.sort_values('decil', ascending=False)\n",
    "\n",
    "# Crear gráficas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "axes[0, 0].plot(fpr, tpr, linewidth=2, color='#2E86AB', label=f'ROC (AUC = {test_auc:.4f})')\n",
    "axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "axes[0, 0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0, 0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0, 0].set_title('ROC Curve - Test Set (XGBoost)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_test_proba)\n",
    "sort_idx = np.argsort(recall)\n",
    "recall_sorted = recall[sort_idx]\n",
    "precision_sorted = precision[sort_idx]\n",
    "\n",
    "axes[0, 1].plot(recall_sorted, precision_sorted, linewidth=2, color='#2E86AB', label=f'PR (AP = {test_ap:.4f})')\n",
    "axes[0, 1].axhline(y=y_test.mean(), color='gray', linestyle='--', linewidth=1, label=f'Baseline ({y_test.mean():.3f})')\n",
    "axes[0, 1].set_xlabel('Recall (TPR)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Precision', fontsize=12)\n",
    "axes[0, 1].set_title('Precision-Recall Curve - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# TPR por Decil\n",
    "axes[1, 0].bar(decil_stats['decil'], decil_stats['tpr'], color='#2E86AB', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Decil de Score (10 = Mayor Riesgo)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "axes[1, 0].set_title('TPR por Decil de Probabilidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(range(1, 11))\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "for i, row in decil_stats.iterrows():\n",
    "    axes[1, 0].text(row['decil'], row['tpr'] + 0.02, f\"{row['tpr']:.2f}\", \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Feature Importance (Top 15)\n",
    "top_features = feature_importance.head(15)\n",
    "axes[1, 1].barh(range(len(top_features)), top_features['Importancia'].values, color='#2E86AB', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_yticks(range(len(top_features)))\n",
    "axes[1, 1].set_yticklabels(top_features['Variable'].values)\n",
    "axes[1, 1].set_xlabel('Importancia (Gain)', fontsize=12)\n",
    "axes[1, 1].set_title('Top 15 Variables Mas Importantes', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/xgboost1_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Graficas guardadas: {OUTPUT_DIR}/xgboost1_curves.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Imprimir tabla de deciles\n",
    "print(\"\\nTabla de TPR por Decil:\")\n",
    "print(decil_stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 15. GUARDAR MODELO Y RESULTADOS\n",
    "# =============================================================================\n",
    "print(\"\\n[15/15] Guardando modelo y resultados...\")\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/xgboost1_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/label_encoders_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "feature_importance.to_csv(f'{OUTPUT_DIR}/feature_importance_xgb1.csv', index=False)\n",
    "\n",
    "test_predictions = pd.DataFrame({\n",
    "    'SK_ID_CURR': df.iloc[X_test.index]['SK_ID_CURR'].values,\n",
    "    'TARGET_Real': y_test.values,\n",
    "    'TARGET_Predicho': y_test_pred,\n",
    "    'Probabilidad_Default': y_test_proba\n",
    "})\n",
    "test_predictions.to_csv(f'{OUTPUT_DIR}/test_predictions_xgb1.csv', index=False)\n",
    "\n",
    "print(f\"Archivos guardados en: {OUTPUT_DIR}/\")\n",
    "print(\"  - xgboost1_model.pkl\")\n",
    "print(\"  - label_encoders_xgb.pkl\")\n",
    "print(\"  - feature_importance_xgb1.csv\")\n",
    "print(\"  - test_predictions_xgb1.csv\")\n",
    "print(\"  - xgboost1_curves.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESUMEN FINAL - XGBOOST 1\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS COMPLETADO - XGBOOST 1\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTipo de problema: CLASIFICACIÓN BINARIA\")\n",
    "print(f\"  - Objetivo: Predecir si un cliente hará default (1) o pagará (0)\")\n",
    "print(f\"  - Algoritmo: XGBoost (Extreme Gradient Boosting)\")\n",
    "print(f\"\\nResultados Finales (TEST SET):\")\n",
    "print(f\"  ROC-AUC: {test_auc:.4f}\")\n",
    "print(f\"  Average Precision: {test_ap:.4f}\")\n",
    "print(f\"  Accuracy: {(y_test_pred == y_test).mean():.4f}\")\n",
    "print(f\"\\nConfiguracion del modelo:\")\n",
    "print(f\"  N_ESTIMATORS: {N_ESTIMATORS}\")\n",
    "print(f\"  MAX_DEPTH: {MAX_DEPTH}\")\n",
    "print(f\"  LEARNING_RATE: {LEARNING_RATE}\")\n",
    "print(f\"  MIN_CHILD_WEIGHT: {MIN_CHILD_WEIGHT}\")\n",
    "print(f\"  SUBSAMPLE: {SUBSAMPLE}\")\n",
    "print(f\"  COLSAMPLE_BYTREE: {COLSAMPLE_BYTREE}\")\n",
    "print(f\"\\nArchivos guardados en: {OUTPUT_DIR}/\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61897967",
   "metadata": {},
   "source": [
    "# XGBoost 2 - Modelo con variables reducidas (24 features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# XGBOOST 2 - DROP DE VARIABLES REDUNDANTES/DERIVADAS\n",
    "# =============================================================================\n",
    "# Recargar datos para modelo 2\n",
    "df2 = pd.read_csv(\"../../data/processed/variables.csv\")\n",
    "\n",
    "# Drop de variables redundantes/derivadas (mismas que en Random Forest)\n",
    "df2 = df2.drop(columns=[\n",
    "    # Edad\n",
    "    'DAYS_BIRTH',\n",
    "    \n",
    "    # Montos base\n",
    "    'AMT_CREDIT',\n",
    "    'AMT_INCOME_TOTAL',\n",
    "    'AMT_ANNUITY',\n",
    "    \n",
    "    # Scores individuales\n",
    "    'EXT_SOURCE_1',\n",
    "    'EXT_SOURCE_2',\n",
    "    'EXT_SOURCE_3',\n",
    "    \n",
    "    # Familia\n",
    "    'CNT_FAM_MEMBERS',\n",
    "    \n",
    "    # Activos\n",
    "    'FLAG_OWN_CAR',\n",
    "    'FLAG_OWN_REALTY',\n",
    "    \n",
    "    # Consultas buró total\n",
    "    'TOTAL_CONSULTAS_BURO',\n",
    "    \n",
    "    # Componentes de ratios\n",
    "    'MESES_CON_MORA',\n",
    "    \n",
    "    # Variables binarias derivadas\n",
    "    'TIENE_IMPAGOS',\n",
    "    'ES_PRIMER_CREDITO',\n",
    "    \n",
    "    # Créditos buró\n",
    "    'CANTIDAD_CREDITOS_BURO'\n",
    "])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"XGBOOST 2 - MODELO CON VARIABLES REDUCIDAS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset despues de drop: {df2.shape}\")\n",
    "print(f\"Variables eliminadas: 15\")\n",
    "print(f\"Variables restantes: {len(df2.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPARACIÓN DE DATOS - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[2/15] Preparando datos para modelo 2...\")\n",
    "\n",
    "X2 = df2.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "y2 = df2['TARGET']\n",
    "\n",
    "print(f\"Variables predictoras: {X2.shape[1]}\")\n",
    "print(f\"Variable objetivo: {y2.name}\")\n",
    "\n",
    "numeric_vars2 = X2.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_vars2 = X2.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Variables numericas: {len(numeric_vars2)}\")\n",
    "print(f\"Variables categoricas: {len(categorical_vars2)}\")\n",
    "print(f\"\\nVariables en el modelo:\")\n",
    "for i, col in enumerate(X2.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b757681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MANEJO DE VALORES FALTANTES - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[3/15] Analizando valores faltantes...\")\n",
    "\n",
    "missing_pct2 = (X2.isnull().sum() / len(X2) * 100).sort_values(ascending=False)\n",
    "missing_vars2 = missing_pct2[missing_pct2 > 0]\n",
    "\n",
    "if len(missing_vars2) > 0:\n",
    "    print(f\"Variables con valores faltantes: {len(missing_vars2)}\")\n",
    "    print(missing_vars2.head(10))\n",
    "    \n",
    "    print(\"\\nImputando valores faltantes...\")\n",
    "    for col in numeric_vars2:\n",
    "        if X2[col].isnull().sum() > 0:\n",
    "            X2[col].fillna(X2[col].median(), inplace=True)\n",
    "    \n",
    "    for col in categorical_vars2:\n",
    "        if X2[col].isnull().sum() > 0:\n",
    "            X2[col].fillna(X2[col].mode()[0], inplace=True)\n",
    "    \n",
    "    print(\"Valores faltantes imputados\")\n",
    "else:\n",
    "    print(\"No hay valores faltantes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2717006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CODIFICACIÓN DE VARIABLES CATEGÓRICAS - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[4/15] Codificando variables categoricas...\")\n",
    "\n",
    "label_encoders2 = {}\n",
    "\n",
    "if len(categorical_vars2) > 0:\n",
    "    for col in categorical_vars2:\n",
    "        le = LabelEncoder()\n",
    "        X2[col] = le.fit_transform(X2[col].astype(str))\n",
    "        label_encoders2[col] = le\n",
    "    \n",
    "    print(f\"{len(categorical_vars2)} variables codificadas\")\n",
    "    print(f\"Categorias: {categorical_vars2}\")\n",
    "else:\n",
    "    print(\"No hay variables categoricas para codificar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a29a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DIVISIÓN TRAIN/TEST - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[5/15] Dividiendo datos en Train/Test...\")\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, \n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y2\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X2_train.shape[0]:,} usuarios ({X2_train.shape[0]/len(X2)*100:.1f}%)\")\n",
    "print(f\"Test set:  {X2_test.shape[0]:,} usuarios ({X2_test.shape[0]/len(X2)*100:.1f}%)\")\n",
    "print(f\"\\nDistribucion TARGET en Train:\")\n",
    "print(f\"  Clase 0 (Pago): {(y2_train==0).sum():,} ({(y2_train==0).sum()/len(y2_train)*100:.2f}%)\")\n",
    "print(f\"  Clase 1 (Default): {(y2_train==1).sum():,} ({(y2_train==1).sum()/len(y2_train)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a911d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENTRENAMIENTO DEL MODELO XGBOOST 2\n",
    "# =============================================================================\n",
    "print(\"\\n[7/15] Entrenando XGBoost 2 (variables reducidas)...\")\n",
    "\n",
    "# Calcular scale_pos_weight\n",
    "scale_pos_weight2 = (y2_train == 0).sum() / (y2_train == 1).sum()\n",
    "\n",
    "model2 = xgb.XGBClassifier(\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    min_child_weight=MIN_CHILD_WEIGHT,\n",
    "    subsample=SUBSAMPLE,\n",
    "    colsample_bytree=COLSAMPLE_BYTREE,\n",
    "    scale_pos_weight=scale_pos_weight2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "model2.fit(X2_train, y2_train)\n",
    "\n",
    "print(\"\\nModelo 2 entrenado exitosamente\")\n",
    "print(f\"Numero de arboles: {model2.n_estimators}\")\n",
    "print(f\"Profundidad maxima: {model2.max_depth}\")\n",
    "print(f\"Learning rate: {model2.learning_rate}\")\n",
    "print(f\"Variables usadas: {X2.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VALIDACIÓN CRUZADA - MODELO 2\n",
    "# =============================================================================\n",
    "print(f\"\\n[8/15] Validacion Cruzada ({CV_FOLDS}-fold en Train)...\")\n",
    "\n",
    "cv_scores2 = cross_val_score(\n",
    "    model2, X2_train, y2_train, \n",
    "    cv=CV_FOLDS, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"ROC-AUC por fold: {cv_scores2}\")\n",
    "print(f\"Media: {cv_scores2.mean():.4f} (+/- {cv_scores2.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71813c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICCIONES - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[9/15] Generando predicciones...\")\n",
    "\n",
    "y2_train_pred = model2.predict(X2_train)\n",
    "y2_train_proba = model2.predict_proba(X2_train)[:, 1]\n",
    "\n",
    "y2_test_pred = model2.predict(X2_test)\n",
    "y2_test_proba = model2.predict_proba(X2_test)[:, 1]\n",
    "\n",
    "print(\"Predicciones generadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACIÓN EN TRAIN - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[10/15] Evaluando modelo 2 en TRAIN SET...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train2_auc = roc_auc_score(y2_train, y2_train_proba)\n",
    "train2_ap = average_precision_score(y2_train, y2_train_proba)\n",
    "\n",
    "print(f\"\\nMetricas Globales:\")\n",
    "print(f\"ROC-AUC Score: {train2_auc:.4f}\")\n",
    "print(f\"Average Precision: {train2_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y2_train, y2_train_pred, \n",
    "                          target_names=['Pago (0)', 'Default (1)']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm2_train = confusion_matrix(y2_train, y2_train_pred)\n",
    "print(cm2_train)\n",
    "print(f\"\\nInterpretacion:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {cm2_train[0,0]:,} - Predijo 'Pago' y si pago\")\n",
    "print(f\"  Falsos Positivos (FP): {cm2_train[0,1]:,} - Predijo 'Default' pero pago\")\n",
    "print(f\"  Falsos Negativos (FN): {cm2_train[1,0]:,} - Predijo 'Pago' pero hizo default [CRITICO]\")\n",
    "print(f\"  Verdaderos Positivos (TP): {cm2_train[1,1]:,} - Predijo 'Default' y si hizo default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EVALUACIÓN EN TEST - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[11/15] Evaluando modelo 2 en TEST SET (metricas definitivas)...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test2_auc = roc_auc_score(y2_test, y2_test_proba)\n",
    "test2_ap = average_precision_score(y2_test, y2_test_proba)\n",
    "\n",
    "print(f\"\\nMetricas Globales:\")\n",
    "print(f\"ROC-AUC Score: {test2_auc:.4f}\")\n",
    "print(f\"Average Precision: {test2_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y2_test_pred, \n",
    "                          target_names=['Pago (0)', 'Default (1)']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm2_test = confusion_matrix(y2_test, y2_test_pred)\n",
    "print(cm2_test)\n",
    "print(f\"\\nInterpretacion:\")\n",
    "print(f\"  Verdaderos Negativos (TN): {cm2_test[0,0]:,} - Predijo 'Pago' y si pago\")\n",
    "print(f\"  Falsos Positivos (FP): {cm2_test[0,1]:,} - Predijo 'Default' pero pago\")\n",
    "print(f\"  Falsos Negativos (FN): {cm2_test[1,0]:,} - Predijo 'Pago' pero hizo default [CRITICO]\")\n",
    "print(f\"  Verdaderos Positivos (TP): {cm2_test[1,1]:,} - Predijo 'Default' y si hizo default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARACIÓN TRAIN VS TEST - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[12/15] Comparando TRAIN vs TEST (analisis de overfitting)...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Metrica':<25} {'Train':<12} {'Test':<12} {'Diferencia':<12}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'ROC-AUC':<25} {train2_auc:<12.4f} {test2_auc:<12.4f} {abs(train2_auc-test2_auc):<12.4f}\")\n",
    "print(f\"{'Average Precision':<25} {train2_ap:<12.4f} {test2_ap:<12.4f} {abs(train2_ap-test2_ap):<12.4f}\")\n",
    "\n",
    "diff_auc2 = abs(train2_auc - test2_auc)\n",
    "if diff_auc2 < 0.02:\n",
    "    print(\"\\nExcelente generalizacion (diferencia < 2%)\")\n",
    "elif diff_auc2 < 0.05:\n",
    "    print(\"\\nBuena generalizacion (diferencia < 5%)\")\n",
    "elif diff_auc2 < 0.10:\n",
    "    print(\"\\nPosible ligero overfitting (diferencia 5-10%)\")\n",
    "else:\n",
    "    print(\"\\nOverfitting detectado (diferencia > 10%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTANCIA DE VARIABLES - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[13/15] Calculando importancia de variables...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_importance2 = pd.DataFrame({\n",
    "    'Variable': X2.columns,\n",
    "    'Importancia': model2.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 variables mas importantes para predecir default:\\n\")\n",
    "print(feature_importance2.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\nInterpretacion de importancia (Gain):\")\n",
    "print(\"  - Problema de CLASIFICACIÓN BINARIA: predecir 0 (Pago) o 1 (Default)\")\n",
    "print(\"  - Gain mide la mejora promedio en la función objetivo al usar la variable\")\n",
    "print(\"  - Valores mas altos = mayor capacidad para mejorar las predicciones\")\n",
    "print(\"  - Basado en la ganancia promedio en todos los árboles del ensemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZACIONES - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[14/15] Generando visualizaciones...\")\n",
    "\n",
    "# Calcular deciles\n",
    "test_results2 = pd.DataFrame({\n",
    "    'y_true': y2_test,\n",
    "    'y_proba': y2_test_proba\n",
    "})\n",
    "test_results2['decil'] = pd.qcut(test_results2['y_proba'], q=10, labels=False, duplicates='drop') + 1\n",
    "\n",
    "# Calcular TPR por decil\n",
    "decil_stats2 = test_results2.groupby('decil').agg({\n",
    "    'y_true': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "decil_stats2.columns = ['decil', 'positivos', 'total', 'tpr']\n",
    "decil_stats2 = decil_stats2.sort_values('decil', ascending=False)\n",
    "\n",
    "# Crear gráficas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# ROC Curve\n",
    "fpr2, tpr2, _ = roc_curve(y2_test, y2_test_proba)\n",
    "axes[0, 0].plot(fpr2, tpr2, linewidth=2, color='#E94F37', label=f'ROC (AUC = {test2_auc:.4f})')\n",
    "axes[0, 0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "axes[0, 0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0, 0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0, 0].set_title('ROC Curve - Test Set (XGB2 - Variables Reducidas)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision2, recall2, _ = precision_recall_curve(y2_test, y2_test_proba)\n",
    "sort_idx2 = np.argsort(recall2)\n",
    "recall_sorted2 = recall2[sort_idx2]\n",
    "precision_sorted2 = precision2[sort_idx2]\n",
    "\n",
    "axes[0, 1].plot(recall_sorted2, precision_sorted2, linewidth=2, color='#E94F37', label=f'PR (AP = {test2_ap:.4f})')\n",
    "axes[0, 1].axhline(y=y2_test.mean(), color='gray', linestyle='--', linewidth=1, label=f'Baseline ({y2_test.mean():.3f})')\n",
    "axes[0, 1].set_xlabel('Recall (TPR)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Precision', fontsize=12)\n",
    "axes[0, 1].set_title('Precision-Recall Curve - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# TPR por Decil\n",
    "axes[1, 0].bar(decil_stats2['decil'], decil_stats2['tpr'], color='#E94F37', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Decil de Score (10 = Mayor Riesgo)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "axes[1, 0].set_title('TPR por Decil de Probabilidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(range(1, 11))\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "for i, row in decil_stats2.iterrows():\n",
    "    axes[1, 0].text(row['decil'], row['tpr'] + 0.02, f\"{row['tpr']:.2f}\", \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Feature Importance (Top 15)\n",
    "top_features2 = feature_importance2.head(15)\n",
    "axes[1, 1].barh(range(len(top_features2)), top_features2['Importancia'].values, color='#E94F37', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_yticks(range(len(top_features2)))\n",
    "axes[1, 1].set_yticklabels(top_features2['Variable'].values)\n",
    "axes[1, 1].set_xlabel('Importancia (Gain)', fontsize=12)\n",
    "axes[1, 1].set_title('Top 15 Variables Mas Importantes (XGB2)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/xgboost2_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Graficas guardadas: {OUTPUT_DIR}/xgboost2_curves.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Imprimir tabla de deciles\n",
    "print(\"\\nTabla de TPR por Decil:\")\n",
    "print(decil_stats2.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR MODELO Y RESULTADOS - MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n[15/15] Guardando modelo 2 y resultados...\")\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/xgboost2_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model2, f)\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/label_encoders_xgb2.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders2, f)\n",
    "\n",
    "feature_importance2.to_csv(f'{OUTPUT_DIR}/feature_importance_xgb2.csv', index=False)\n",
    "\n",
    "test_predictions2 = pd.DataFrame({\n",
    "    'SK_ID_CURR': df2.iloc[X2_test.index]['SK_ID_CURR'].values,\n",
    "    'TARGET_Real': y2_test.values,\n",
    "    'TARGET_Predicho': y2_test_pred,\n",
    "    'Probabilidad_Default': y2_test_proba\n",
    "})\n",
    "test_predictions2.to_csv(f'{OUTPUT_DIR}/test_predictions_xgb2.csv', index=False)\n",
    "\n",
    "print(f\"Archivos guardados en: {OUTPUT_DIR}/\")\n",
    "print(\"  - xgboost2_model.pkl\")\n",
    "print(\"  - label_encoders_xgb2.pkl\")\n",
    "print(\"  - feature_importance_xgb2.csv\")\n",
    "print(\"  - test_predictions_xgb2.csv\")\n",
    "print(\"  - xgboost2_curves.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARACIÓN MODELO 1 VS MODELO 2\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACIÓN: XGBOOST 1 (39 vars) VS XGBOOST 2 (24 vars)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Metrica':<25} {'XGB1 (39 vars)':<15} {'XGB2 (24 vars)':<15} {'Diferencia':<12}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'ROC-AUC (Test)':<25} {test_auc:<15.4f} {test2_auc:<15.4f} {test2_auc - test_auc:<12.4f}\")\n",
    "print(f\"{'Average Precision (Test)':<25} {test_ap:<15.4f} {test2_ap:<15.4f} {test2_ap - test_ap:<12.4f}\")\n",
    "print(f\"{'ROC-AUC (Train)':<25} {train_auc:<15.4f} {train2_auc:<15.4f} {train2_auc - train_auc:<12.4f}\")\n",
    "print(f\"{'Overfitting (Train-Test)':<25} {train_auc - test_auc:<15.4f} {train2_auc - test2_auc:<15.4f}\")\n",
    "\n",
    "print(f\"\\nNumero de variables:\")\n",
    "print(f\"  Modelo 1: {X.shape[1]} variables\")\n",
    "print(f\"  Modelo 2: {X2.shape[1]} variables\")\n",
    "print(f\"  Reduccion: {X.shape[1] - X2.shape[1]} variables eliminadas ({(X.shape[1] - X2.shape[1])/X.shape[1]*100:.1f}%)\")\n",
    "\n",
    "# Conclusión\n",
    "if test2_auc >= test_auc:\n",
    "    print(f\"\\n✓ Modelo 2 tiene MEJOR o IGUAL rendimiento con menos variables\")\n",
    "    print(f\"  Esto sugiere que las variables eliminadas eran redundantes\")\n",
    "else:\n",
    "    print(f\"\\n✗ Modelo 2 tiene PEOR rendimiento\")\n",
    "    print(f\"  Diferencia de AUC: {test_auc - test2_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALISIS COMPLETADO - XGBOOST (AMBOS MODELOS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nConfiguracion de hiperparametros (ambos modelos):\")\n",
    "print(f\"  N_ESTIMATORS: {N_ESTIMATORS}\")\n",
    "print(f\"  MAX_DEPTH: {MAX_DEPTH}\")\n",
    "print(f\"  LEARNING_RATE: {LEARNING_RATE}\")\n",
    "print(f\"  MIN_CHILD_WEIGHT: {MIN_CHILD_WEIGHT}\")\n",
    "print(f\"  SUBSAMPLE: {SUBSAMPLE}\")\n",
    "print(f\"  COLSAMPLE_BYTREE: {COLSAMPLE_BYTREE}\")\n",
    "print(f\"\\nArchivos guardados en: {OUTPUT_DIR}/\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aplicada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
