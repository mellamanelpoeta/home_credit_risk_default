{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Predicción de Riesgo de Impago Crediticio\"\n",
        "subtitle: \"Home Credit Default Risk - Un Enfoque Multivariado\"\n",
        "author:\n",
        "  - name: \"Gerardo Guerrero\"\n",
        "  - name: \"Juan Pablo Cordero\"\n",
        "  - name: \"Jerónimo Deli\"\n",
        "  - name: \"Romain S\"\n",
        "date: \"Diciembre 2025\"\n",
        "format:\n",
        "  html:\n",
        "    theme: cosmo\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    number-sections: true\n",
        "    code-fold: true\n",
        "    fig-cap-location: bottom\n",
        "  pdf:\n",
        "    documentclass: article\n",
        "    geometry: margin=2.5cm\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  error: false\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "XGBoostError",
          "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     classification_report, confusion_matrix, roc_auc_score, \n\u001b[1;32m     12\u001b[0m     roc_curve, precision_recall_curve, average_precision_score\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n",
            "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/core.py:269\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/core.py:222\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    221\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(ver: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
            "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <89AD948E-E564-3266-867D-7AF89D6488F0> /Users/juan.cordero/Documents/itam/home_credit_risk_default/aplicada/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score, \n",
        "    roc_curve, precision_recall_curve, average_precision_score\n",
        ")\n",
        "from IPython.display import display, Markdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuración de visualización\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "sns.set_palette('husl')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introducción\n",
        "\n",
        "## Contexto del Problema\n",
        "\n",
        "El acceso al crédito es un pilar fundamental para el desarrollo económico individual y colectivo. Sin embargo, las instituciones financieras enfrentan el desafío constante de evaluar el **riesgo de incumplimiento** (*default*) de sus clientes. Una evaluación inadecuada puede resultar en pérdidas significativas para la institución o, por otro lado, en la exclusión financiera de personas que podrían cumplir con sus obligaciones.\n",
        "\n",
        "**Home Credit Group** es una compañía de servicios financieros enfocada en préstamos a poblaciones no bancarizadas o con historial crediticio limitado. El problema que abordamos es la **predicción del riesgo de impago** utilizando técnicas estadísticas multivariadas, con el objetivo de:\n",
        "\n",
        "1. **Identificar clientes con alta probabilidad de incumplimiento** antes de otorgar el crédito\n",
        "2. **Comprender los factores que influyen en el impago** para diseñar políticas de mitigación\n",
        "3. **Equilibrar la inclusión financiera con la gestión del riesgo**\n",
        "\n",
        "## Marco Conceptual: El Grafo Causal del Impago\n",
        "\n",
        "Antes de desarrollar nuestros modelos predictivos, construimos un **grafo causal** que representa nuestra comprensión teórica del fenómeno. Este ejercicio de pensamiento causal nos permite identificar las variables relevantes y sus relaciones, fundamentando así nuestro enfoque analítico.\n",
        "\n",
        "### Modelo Causal Simplificado\n",
        "\n",
        "El impago crediticio puede originarse por dos vías principales:\n",
        "\n",
        "- **Fraude**: Cuando el cliente nunca tuvo intención de pagar\n",
        "- **Capacidad de Pago**: Cuando el cliente no puede cumplir con sus obligaciones debido a restricciones económicas\n",
        "\n",
        "El grafo causal detallado nos muestra las relaciones entre las distintas variables que capturamos en los datos y cómo estas se relacionan con los dos mecanismos principales de impago.\n",
        "\n",
        "## Hipótesis de Investigación\n",
        "\n",
        "Con base en el marco causal, formulamos las siguientes hipótesis que guiarán nuestro análisis:\n",
        "\n",
        "| Hipótesis | Variable Proxy | Relación Esperada |\n",
        "|-----------|----------------|-------------------|\n",
        "| Préstamos más altos incrementan la probabilidad de impago | `AMT_CREDIT` | Positiva |\n",
        "| Menor edad y sin historial crediticio aumenta el riesgo | `EDAD_ANOS`, `ES_PRIMER_CREDITO` | Negativa, Positiva |\n",
        "| Mal historial crediticio incrementa el riesgo | `EXT_SOURCE_1/2/3`, `SCORE_PROMEDIO` | Negativa |\n",
        "| Menor ingreso incrementa el riesgo | `AMT_INCOME_TOTAL`, `INGRESO_PER_CAPITA` | Negativa |\n",
        "| Mayor carga de gastos incrementa el riesgo | `CNT_CHILDREN`, `CNT_FAM_MEMBERS` | Positiva |\n",
        "| Mayor deuda acumulada incrementa el riesgo | `TOTAL_DEUDA_ACTUAL`, `CREDITOS_ACTIVOS` | Positiva |\n",
        "| Menos activos incrementan el riesgo | `NUM_ACTIVOS`, `FLAG_OWN_CAR`, `FLAG_OWN_REALTY` | Negativa |\n",
        "| Condiciones crediticias adversas aumentan el riesgo | `TASA_INTERES_PROMEDIO`, `PLAZO_PROMEDIO` | Positiva |\n",
        "\n",
        "## Preguntas de Investigación\n",
        "\n",
        "1. ¿Cuáles son las variables con mayor poder predictivo para identificar clientes en riesgo de impago?\n",
        "2. ¿Qué modelo (Regresión Logística, Random Forest o XGBoost) ofrece el mejor balance entre interpretabilidad y poder predictivo?\n",
        "3. ¿Podemos reducir la dimensionalidad del problema sin perder capacidad predictiva?\n",
        "\n",
        "# Variables Disponibles\n",
        "\n",
        "## Descripción del Dataset\n",
        "\n",
        "El conjunto de datos proviene de la competencia [Home Credit Default Risk](https://www.kaggle.com/competitions/home-credit-default-risk) de Kaggle. La estructura de datos incluye múltiples tablas relacionadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "datasets_info = pd.DataFrame({\n",
        "    'Tabla': ['application_train.csv', 'bureau.csv', 'bureau_balance.csv', \n",
        "              'previous_application.csv', 'installments_payments.csv', 'credit_card_balance.csv'],\n",
        "    'Descripción': ['Información principal de las solicitudes', \n",
        "                    'Historial crediticio de otras instituciones',\n",
        "                    'Balance mensual de créditos en buró',\n",
        "                    'Solicitudes previas en Home Credit',\n",
        "                    'Historial de pagos',\n",
        "                    'Balance de tarjetas de crédito'],\n",
        "    'Registros': ['307,511', '1,716,428', '27,299,925', \n",
        "                  '1,670,214', '13,605,401', '3,840,312']\n",
        "})\n",
        "\n",
        "display(datasets_info.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables Originales de Application Train\n",
        "\n",
        "La tabla principal `application_train.csv` contiene 122 variables que se pueden agrupar en las siguientes categorías:\n",
        "\n",
        "### Variables Demográficas\n",
        "- `CODE_GENDER`: Género del solicitante\n",
        "- `DAYS_BIRTH`: Edad en días (negativo)\n",
        "- `NAME_FAMILY_STATUS`: Estado civil\n",
        "- `CNT_CHILDREN`: Número de hijos\n",
        "- `CNT_FAM_MEMBERS`: Número de miembros en la familia\n",
        "- `NAME_EDUCATION_TYPE`: Nivel educativo\n",
        "- `NAME_INCOME_TYPE`: Tipo de ingreso\n",
        "\n",
        "### Variables Financieras\n",
        "- `AMT_INCOME_TOTAL`: Ingreso total del solicitante\n",
        "- `AMT_CREDIT`: Monto del crédito solicitado\n",
        "- `AMT_ANNUITY`: Anualidad del préstamo\n",
        "- `AMT_GOODS_PRICE`: Precio del bien a comprar\n",
        "\n",
        "### Scores de Riesgo Externos\n",
        "- `EXT_SOURCE_1`: Score externo fuente 1\n",
        "- `EXT_SOURCE_2`: Score externo fuente 2\n",
        "- `EXT_SOURCE_3`: Score externo fuente 3\n",
        "\n",
        "### Variables de Activos\n",
        "- `FLAG_OWN_CAR`: Si posee automóvil\n",
        "- `FLAG_OWN_REALTY`: Si posee propiedad inmobiliaria\n",
        "- `OWN_CAR_AGE`: Edad del automóvil\n",
        "\n",
        "### Variables de Contacto y Documentación\n",
        "- `FLAG_MOBIL`: Si tiene teléfono móvil\n",
        "- `FLAG_EMAIL`: Si tiene correo electrónico\n",
        "- `FLAG_DOCUMENT_*`: Serie de flags para documentos proporcionados\n",
        "\n",
        "### Variables de Vivienda\n",
        "- `NAME_HOUSING_TYPE`: Tipo de vivienda\n",
        "- `REGION_POPULATION_RELATIVE`: Población relativa de la región\n",
        "- `REGION_RATING_CLIENT`: Rating de la región del cliente\n",
        "\n",
        "### Consultas al Buró\n",
        "- `AMT_REQ_CREDIT_BUREAU_HOUR/DAY/WEEK/MON/QRT/YEAR`: Consultas al buró en diferentes periodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "resumen = pd.DataFrame({\n",
        "    'Característica': ['Total de usuarios', 'Variables originales', 'Variables seleccionadas', \n",
        "                       'Tasa de Default', 'División Train/Test'],\n",
        "    'Valor': ['307,511', '122+', '24-39', '8.07%', '80% / 20%']\n",
        "})\n",
        "\n",
        "display(resumen.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribución de la Variable Objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "target_dist = pd.DataFrame({\n",
        "    'Clase': ['No Default (0)', 'Default (1)'],\n",
        "    'Cantidad': [282686, 24825],\n",
        "    'Porcentaje': [91.93, 8.07]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "colors = ['#3498db', '#e74c3c']\n",
        "bars = ax.bar(target_dist['Clase'], target_dist['Cantidad'], color=colors, edgecolor='black')\n",
        "ax.set_ylabel('Número de Clientes')\n",
        "ax.set_title('Distribución de Clases')\n",
        "for i, (q, p) in enumerate(zip(target_dist['Cantidad'], target_dist['Porcentaje'])):\n",
        "    ax.text(i, q + 5000, f'{q:,}\\n({p:.1f}%)', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset presenta un **desbalance significativo** con solo el 8.07% de casos positivos (default). Este desbalance tiene implicaciones importantes:\n",
        "\n",
        "1. Métricas como *accuracy* son engañosas (un modelo que predice siempre \"no default\" tendría 92% de accuracy)\n",
        "2. Debemos usar técnicas como `class_weight='balanced'` o `scale_pos_weight` en los modelos\n",
        "3. Las métricas PR-AUC y Recall son más informativas que ROC-AUC\n",
        "\n",
        "# Variables Seleccionadas y Construidas\n",
        "\n",
        "## Ingeniería de Variables\n",
        "\n",
        "A partir de las tablas relacionadas, construimos 41 variables que capturan diferentes dimensiones del riesgo crediticio:\n",
        "\n",
        "### Variables Demográficas y Socioeconómicas\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `EDAD_ANOS` | Edad del solicitante en años | Derivada de `DAYS_BIRTH` |\n",
        "| `CNT_CHILDREN` | Número de hijos | Original |\n",
        "| `CODE_GENDER` | Género | Original |\n",
        "| `NAME_FAMILY_STATUS` | Estado civil | Original |\n",
        "| `NAME_EDUCATION_TYPE` | Nivel educativo | Original |\n",
        "\n",
        "### Variables Financieras\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `AMT_CREDIT` | Monto del crédito solicitado | Original |\n",
        "| `AMT_INCOME_TOTAL` | Ingreso total declarado | Original |\n",
        "| `AMT_ANNUITY` | Anualidad del préstamo | Original |\n",
        "| `CREDIT_INCOME_RATIO` | Ratio crédito/ingreso | **Construida** |\n",
        "| `INGRESO_PER_CAPITA` | Ingreso por miembro de familia | **Construida** |\n",
        "\n",
        "### Scores de Riesgo Externos\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `EXT_SOURCE_1` | Score externo fuente 1 | Original |\n",
        "| `EXT_SOURCE_2` | Score externo fuente 2 | Original |\n",
        "| `EXT_SOURCE_3` | Score externo fuente 3 | Original |\n",
        "| `SCORE_PROMEDIO` | Promedio de los tres scores externos | **Construida** |\n",
        "\n",
        "### Historial Crediticio (desde Bureau)\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `CREDITOS_ACTIVOS` | Número de créditos activos en buró | **Construida** |\n",
        "| `CREDITOS_CERRADOS` | Número de créditos cerrados en buró | **Construida** |\n",
        "| `TOTAL_CREDITO_OTORGADO` | Suma histórica de créditos | **Construida** |\n",
        "| `TOTAL_DEUDA_ACTUAL` | Deuda vigente total | **Construida** |\n",
        "| `PCT_MESES_MORA` | Porcentaje de meses con mora histórica | **Construida** |\n",
        "| `CREDITOS_CON_IMPAGO` | Número de créditos con historial de impago | **Construida** |\n",
        "| `MAX_DIAS_MORA` | Máximo de días en mora | **Construida** |\n",
        "\n",
        "### Variables de Préstamos Previos\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `NUM_PRESTAMOS_PREVIOS` | Cantidad de préstamos anteriores | **Construida** |\n",
        "| `TASA_INTERES_PROMEDIO` | Tasa de interés promedio histórica | **Construida** |\n",
        "| `PLAZO_PROMEDIO` | Plazo promedio de créditos previos | **Construida** |\n",
        "| `MONTO_PROMEDIO_PREVIO` | Monto promedio de créditos previos | **Construida** |\n",
        "| `TOTAL_CREDITO_HISTORICO` | Suma total de créditos históricos | **Construida** |\n",
        "\n",
        "### Variables de Comportamiento de Pago\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `RATIO_PAGO_CUOTA` | Ratio pago realizado / cuota programada | **Construida** |\n",
        "| `RATIO_PAGO_MINIMO_TC` | Ratio de pago mínimo en tarjetas | **Construida** |\n",
        "\n",
        "### Variables de Activos\n",
        "\n",
        "| Variable | Descripción | Origen |\n",
        "|----------|-------------|--------|\n",
        "| `FLAG_OWN_CAR` | Posesión de automóvil | Original |\n",
        "| `FLAG_OWN_REALTY` | Posesión de inmueble | Original |\n",
        "| `NUM_ACTIVOS` | Suma de activos poseídos (0, 1 o 2) | **Construida** |\n",
        "\n",
        "## Código de Generación de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# GENERACIÓN DE FEATURES - VERSIÓN OPTIMIZADA\n",
        "# ============================================================================\n",
        "\n",
        "# PARTE 1: FEATURES BASE DE APPLICATION\n",
        "df = app_train[['SK_ID_CURR', 'TARGET']].copy()\n",
        "\n",
        "# Features básicas\n",
        "df['AMT_CREDIT'] = app_train['AMT_CREDIT']\n",
        "df['AMT_ANNUITY'] = app_train['AMT_ANNUITY']\n",
        "df['AMT_INCOME_TOTAL'] = app_train['AMT_INCOME_TOTAL']\n",
        "\n",
        "# Edad\n",
        "df['DAYS_BIRTH'] = app_train['DAYS_BIRTH']\n",
        "df['EDAD_ANOS'] = abs(app_train['DAYS_BIRTH']) / 365.25\n",
        "\n",
        "# Scores externos - Promedio\n",
        "df['EXT_SOURCE_1'] = app_train['EXT_SOURCE_1']\n",
        "df['EXT_SOURCE_2'] = app_train['EXT_SOURCE_2']\n",
        "df['EXT_SOURCE_3'] = app_train['EXT_SOURCE_3']\n",
        "df['SCORE_PROMEDIO'] = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "\n",
        "# Ratios financieros\n",
        "df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
        "df['INGRESO_PER_CAPITA'] = np.where(\n",
        "    df['CNT_FAM_MEMBERS'] > 0,\n",
        "    df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS'],\n",
        "    df['AMT_INCOME_TOTAL']\n",
        ")\n",
        "\n",
        "# Activos\n",
        "df['NUM_ACTIVOS'] = (app_train['FLAG_OWN_CAR'] == 'Y').astype(int) + \\\n",
        "                    (app_train['FLAG_OWN_REALTY'] == 'Y').astype(int)\n",
        "\n",
        "# PARTE 2: FEATURES DE BUREAU\n",
        "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
        "    'AMT_CREDIT_SUM': 'sum',\n",
        "    'AMT_CREDIT_SUM_DEBT': 'sum',\n",
        "    'CREDIT_DAY_OVERDUE': 'max',\n",
        "    'SK_ID_BUREAU': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "# Créditos activos y cerrados\n",
        "bureau_active = bureau[bureau['CREDIT_ACTIVE'] == 'Active'].groupby('SK_ID_CURR').size()\n",
        "bureau_closed = bureau[bureau['CREDIT_ACTIVE'] == 'Closed'].groupby('SK_ID_CURR').size()\n",
        "\n",
        "# PARTE 3: FEATURES DE BUREAU BALANCE\n",
        "bureau_balance_merged['EN_MORA'] = bureau_balance_merged['STATUS'].isin(['1', '2', '3', '4', '5'])\n",
        "balance_agg = bureau_balance_merged.groupby('SK_ID_CURR').agg({\n",
        "    'EN_MORA': 'sum',\n",
        "    'STATUS': 'count'\n",
        "})\n",
        "balance_agg['PCT_MESES_MORA'] = (balance_agg['EN_MORA'] / balance_agg['STATUS']) * 100\n",
        "\n",
        "# PARTE 4: FEATURES DE PREVIOUS APPLICATION\n",
        "prev_agg = prev_app.groupby('SK_ID_CURR').agg({\n",
        "    'SK_ID_PREV': 'count',\n",
        "    'RATE_INTEREST_PRIMARY': 'mean',\n",
        "    'CNT_PAYMENT': 'mean',\n",
        "    'AMT_CREDIT': ['mean', 'sum']\n",
        "})\n",
        "\n",
        "# PARTE 5: FEATURES DE INSTALLMENTS\n",
        "valid_installments['PAYMENT_RATIO'] = valid_installments['AMT_PAYMENT'] / valid_installments['AMT_INSTALMENT']\n",
        "install_agg = valid_installments.groupby('SK_ID_CURR')['PAYMENT_RATIO'].mean()\n",
        "\n",
        "# PARTE 6: FEATURES DE CREDIT CARD\n",
        "valid_cc['PAYMENT_MIN_RATIO'] = valid_cc['AMT_PAYMENT_CURRENT'] / valid_cc['AMT_INST_MIN_REGULARITY']\n",
        "cc_agg = valid_cc.groupby('SK_ID_CURR')['PAYMENT_MIN_RATIO'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grafo Causal del Impago\n",
        "\n",
        "El análisis causal nos permite entender las relaciones entre variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Representación visual del grafo causal\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(0, 8)\n",
        "ax.axis('off')\n",
        "\n",
        "# Nodos\n",
        "nodes = {\n",
        "    'Edad': (1, 6),\n",
        "    'Ingreso': (1, 4),\n",
        "    'Educación': (1, 2),\n",
        "    'Historial\\nCrediticio': (4, 6),\n",
        "    'Capacidad\\nde Pago': (4, 4),\n",
        "    'Deuda\\nActual': (4, 2),\n",
        "    'Score\\nExterno': (7, 6),\n",
        "    'Fraude': (7, 4),\n",
        "    'DEFAULT': (9, 4)\n",
        "}\n",
        "\n",
        "# Dibujar nodos\n",
        "for name, (x, y) in nodes.items():\n",
        "    color = '#e74c3c' if name == 'DEFAULT' else '#3498db' if 'Score' in name else '#95a5a6'\n",
        "    circle = plt.Circle((x, y), 0.5, color=color, alpha=0.7)\n",
        "    ax.add_patch(circle)\n",
        "    ax.text(x, y, name, ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
        "\n",
        "# Flechas (conexiones causales)\n",
        "arrows = [\n",
        "    ('Edad', 'Historial\\nCrediticio'),\n",
        "    ('Ingreso', 'Capacidad\\nde Pago'),\n",
        "    ('Educación', 'Capacidad\\nde Pago'),\n",
        "    ('Historial\\nCrediticio', 'Score\\nExterno'),\n",
        "    ('Capacidad\\nde Pago', 'Score\\nExterno'),\n",
        "    ('Deuda\\nActual', 'Capacidad\\nde Pago'),\n",
        "    ('Score\\nExterno', 'DEFAULT'),\n",
        "    ('Fraude', 'DEFAULT'),\n",
        "    ('Capacidad\\nde Pago', 'DEFAULT')\n",
        "]\n",
        "\n",
        "for start, end in arrows:\n",
        "    x1, y1 = nodes[start]\n",
        "    x2, y2 = nodes[end]\n",
        "    ax.annotate('', xy=(x2-0.5, y2), xytext=(x1+0.5, y1),\n",
        "                arrowprops=dict(arrowstyle='->', color='#2c3e50', lw=1.5))\n",
        "\n",
        "ax.set_title('Grafo Causal del Riesgo de Impago', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Subset Final de Variables Utilizadas\n",
        "\n",
        "## Variables Seleccionadas para el Modelado\n",
        "\n",
        "Después del análisis exploratorio y la ingeniería de variables, se seleccionó un subset de **24 variables** para el modelado final:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "variables_finales = pd.DataFrame({\n",
        "    'Variable': ['EDAD_ANOS', 'SCORE_PROMEDIO', 'CREDIT_INCOME_RATIO', 'NAME_FAMILY_STATUS',\n",
        "                 'CNT_CHILDREN', 'CODE_GENDER', 'NAME_EDUCATION_TYPE', 'INGRESO_PER_CAPITA',\n",
        "                 'NUM_ACTIVOS', 'TOTAL_CREDITO_DISPONIBLE', 'TOTAL_CREDITO_OTORGADO',\n",
        "                 'TOTAL_DEUDA_ACTUAL', 'MAX_DIAS_MORA', 'CREDITOS_ACTIVOS', 'CREDITOS_CERRADOS',\n",
        "                 'PCT_MESES_MORA', 'CREDITOS_CON_IMPAGO', 'NUM_PRESTAMOS_PREVIOS',\n",
        "                 'TASA_INTERES_PROMEDIO', 'PLAZO_PROMEDIO', 'MONTO_PROMEDIO_PREVIO',\n",
        "                 'TOTAL_CREDITO_HISTORICO', 'RATIO_PAGO_CUOTA', 'RATIO_PAGO_MINIMO_TC'],\n",
        "    'Tipo': ['Continua', 'Continua [0,1]', 'Continua', 'Categórica',\n",
        "             'Discreta', 'Categórica', 'Categórica', 'Continua',\n",
        "             'Discreta [0,2]', 'Continua', 'Continua',\n",
        "             'Continua', 'Continua', 'Discreta', 'Discreta',\n",
        "             'Continua [0,100]', 'Discreta', 'Discreta',\n",
        "             'Continua', 'Continua', 'Continua',\n",
        "             'Continua', 'Continua', 'Continua'],\n",
        "    'Categoría': ['Demográfica', 'Score', 'Financiera', 'Demográfica',\n",
        "                  'Demográfica', 'Demográfica', 'Demográfica', 'Financiera',\n",
        "                  'Activos', 'Historial', 'Historial',\n",
        "                  'Historial', 'Historial', 'Historial', 'Historial',\n",
        "                  'Historial', 'Historial', 'Préstamos Previos',\n",
        "                  'Préstamos Previos', 'Préstamos Previos', 'Préstamos Previos',\n",
        "                  'Préstamos Previos', 'Comportamiento', 'Comportamiento']\n",
        "})\n",
        "\n",
        "display(variables_finales.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis de Correlaciones\n",
        "\n",
        "### Correlación con la Variable Objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "correlaciones = pd.DataFrame({\n",
        "    'Variable': ['SCORE_PROMEDIO', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'EXT_SOURCE_1', \n",
        "                 'EDAD_ANOS', 'CREDITOS_ACTIVOS', 'CREDITOS_CERRADOS', 'PCT_MESES_MORA',\n",
        "                 'ES_PRIMER_CREDITO', 'AMT_CREDIT', 'TIENE_IMPAGOS', 'PLAZO_PROMEDIO',\n",
        "                 'NUM_PRESTAMOS_PREVIOS', 'CREDITOS_CON_IMPAGO', 'NUM_ACTIVOS'],\n",
        "    'Correlacion': [-0.222, -0.179, -0.161, -0.155, -0.078, 0.044, -0.037, 0.032,\n",
        "                    0.031, -0.030, 0.030, 0.028, 0.024, 0.021, -0.020]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "colors = ['#e74c3c' if x > 0 else '#3498db' for x in correlaciones['Correlacion']]\n",
        "bars = ax.barh(correlaciones['Variable'], correlaciones['Correlacion'], color=colors, edgecolor='black')\n",
        "\n",
        "ax.axvline(x=0, color='black', linewidth=1)\n",
        "ax.axvline(x=0.1, color='gray', linestyle='--', alpha=0.5, label='Umbral moderado')\n",
        "ax.axvline(x=-0.1, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "ax.set_xlabel('Correlación con TARGET')\n",
        "ax.set_title('Correlación de Variables con Riesgo de Default')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, correlaciones['Correlacion']):\n",
        "    ax.text(val + 0.005 if val > 0 else val - 0.005, bar.get_y() + bar.get_height()/2,\n",
        "            f'{val:.3f}', va='center', ha='left' if val > 0 else 'right', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hallazgos clave del análisis de correlación:**\n",
        "\n",
        "1. **Variables con mayor poder predictivo (|r| > 0.1)**:\n",
        "   - `SCORE_PROMEDIO` (r = -0.222): El promedio de scores externos es el mejor predictor individual\n",
        "   - `EXT_SOURCE_3` (r = -0.179), `EXT_SOURCE_2` (r = -0.161), `EXT_SOURCE_1` (r = -0.155)\n",
        "\n",
        "2. **Variables demográficas**:\n",
        "   - `EDAD_ANOS` (r = -0.078): Clientes más jóvenes tienen mayor probabilidad de default\n",
        "\n",
        "3. **Variables de historial crediticio**:\n",
        "   - `CREDITOS_ACTIVOS` (r = +0.044): Más créditos activos aumentan el riesgo\n",
        "   - `PCT_MESES_MORA` (r = +0.032): El historial de mora es indicativo de riesgo futuro\n",
        "\n",
        "### Matriz de Correlación (Heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Datos de correlación top\n",
        "top_corr_data = {\n",
        "    'Variables': ['TOTAL_CREDITO_HISTORICO - NUM_PRESTAMOS_PREVIOS',\n",
        "                  'TOTAL_CREDITO_HISTORICO - MONTO_PROMEDIO_PREVIO',\n",
        "                  'MONTO_PROMEDIO_PREVIO - PLAZO_PROMEDIO',\n",
        "                  'TOTAL_DEUDA_ACTUAL - TOTAL_CREDITO_OTORGADO',\n",
        "                  'TOTAL_CREDITO_HISTORICO - PLAZO_PROMEDIO',\n",
        "                  'CREDITOS_CON_IMPAGO - PCT_MESES_MORA',\n",
        "                  'CREDITOS_CERRADOS - CREDITOS_ACTIVOS',\n",
        "                  'CNT_CHILDREN - EDAD_ANOS',\n",
        "                  'CREDITOS_CERRADOS - TOTAL_CREDITO_OTORGADO',\n",
        "                  'CREDITOS_ACTIVOS - TOTAL_CREDITO_OTORGADO'],\n",
        "    'Correlación': [0.701, 0.659, 0.602, 0.582, 0.507, 0.462, 0.456, -0.331, 0.309, 0.307]\n",
        "}\n",
        "\n",
        "top_corr = pd.DataFrame(top_corr_data)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "colors = ['#e74c3c' if c > 0 else '#3498db' for c in top_corr['Correlación']]\n",
        "bars = ax.barh(range(len(top_corr)), top_corr['Correlación'], color=colors, edgecolor='black', alpha=0.7)\n",
        "ax.set_yticks(range(len(top_corr)))\n",
        "ax.set_yticklabels(top_corr['Variables'], fontsize=9)\n",
        "ax.set_xlabel('Correlación')\n",
        "ax.set_title('Top 10 Pares de Variables Más Correlacionados')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "ax.axvline(x=0, color='black', linewidth=1)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars, top_corr['Correlación'])):\n",
        "    ax.text(val + 0.02, i, f'{val:.2f}', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparación de Perfiles: Default vs. No Default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "comparacion = pd.DataFrame({\n",
        "    'Variable': ['EDAD_ANOS', 'CREDIT_INCOME_RATIO', 'SCORE_PROMEDIO', 'TOTAL_DEUDA_ACTUAL',\n",
        "                 'CREDITOS_ACTIVOS', 'PCT_MESES_MORA', 'CREDITOS_CON_IMPAGO', 'NUM_ACTIVOS',\n",
        "                 'RATIO_PAGO_CUOTA', 'RATIO_PAGO_MINIMO_TC'],\n",
        "    'Pagó (0)': [44.18, 3.96, 0.52, 548083, 1.74, 0.50, 0.22, 1.04, 1.37, 21.60],\n",
        "    'Default (1)': [40.75, 3.89, 0.40, 558718, 2.03, 0.87, 0.28, 0.99, 1.52, 6.28],\n",
        "    '% Cambio': [-7.77, -1.93, -23.52, 1.94, 16.60, 73.41, 31.27, -4.67, 10.97, -70.93]\n",
        "})\n",
        "\n",
        "display(comparacion.style.hide(axis='index')\n",
        "        .format({'Pagó (0)': '{:.2f}', 'Default (1)': '{:.2f}', '% Cambio': '{:+.2f}%'})\n",
        "        .background_gradient(subset=['% Cambio'], cmap='RdYlGn_r', vmin=-50, vmax=50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Perfil del cliente en riesgo de default:**\n",
        "\n",
        "- **Más joven** (40.8 años vs 44.2 años, -7.8%)\n",
        "- **Menor score crediticio** (0.40 vs 0.52, -23.5%)\n",
        "- **Más créditos activos** (2.03 vs 1.74, +16.6%)\n",
        "- **Mayor historial de mora** (0.87% vs 0.50%, +73.4%)\n",
        "- **Menor ratio de pago mínimo en tarjetas** (6.28 vs 21.60, -70.9%)\n",
        "\n",
        "# Variables Descartadas\n",
        "\n",
        "## Lista de Variables Eliminadas\n",
        "\n",
        "Se eliminaron **15 variables** del dataset original por ser redundantes o derivadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "variables_drop = pd.DataFrame({\n",
        "    'Variable': ['DAYS_BIRTH', 'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'AMT_ANNUITY',\n",
        "                 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'CNT_FAM_MEMBERS',\n",
        "                 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'TOTAL_CONSULTAS_BURO',\n",
        "                 'MESES_CON_MORA', 'TIENE_IMPAGOS', 'ES_PRIMER_CREDITO', 'CANTIDAD_CREDITOS_BURO'],\n",
        "    'Razón de Eliminación': [\n",
        "        'Redundante - se usa EDAD_ANOS derivada',\n",
        "        'Redundante - capturada en CREDIT_INCOME_RATIO',\n",
        "        'Redundante - capturada en CREDIT_INCOME_RATIO e INGRESO_PER_CAPITA',\n",
        "        'Baja correlación con TARGET',\n",
        "        'Redundante - incluida en SCORE_PROMEDIO',\n",
        "        'Redundante - incluida en SCORE_PROMEDIO',\n",
        "        'Redundante - incluida en SCORE_PROMEDIO',\n",
        "        'Redundante - usada para calcular INGRESO_PER_CAPITA',\n",
        "        'Redundante - incluida en NUM_ACTIVOS',\n",
        "        'Redundante - incluida en NUM_ACTIVOS',\n",
        "        'Baja correlación con TARGET',\n",
        "        'Redundante - usada para calcular PCT_MESES_MORA',\n",
        "        'Derivada de MAX_DIAS_MORA',\n",
        "        'Derivada de CANTIDAD_CREDITOS_BURO',\n",
        "        'Baja correlación con TARGET'\n",
        "    ],\n",
        "    'Alternativa Usada': [\n",
        "        'EDAD_ANOS',\n",
        "        'CREDIT_INCOME_RATIO',\n",
        "        'CREDIT_INCOME_RATIO, INGRESO_PER_CAPITA',\n",
        "        '-',\n",
        "        'SCORE_PROMEDIO',\n",
        "        'SCORE_PROMEDIO',\n",
        "        'SCORE_PROMEDIO',\n",
        "        'INGRESO_PER_CAPITA',\n",
        "        'NUM_ACTIVOS',\n",
        "        'NUM_ACTIVOS',\n",
        "        '-',\n",
        "        'PCT_MESES_MORA',\n",
        "        'MAX_DIAS_MORA',\n",
        "        'CREDITOS_ACTIVOS, CREDITOS_CERRADOS',\n",
        "        'CREDITOS_ACTIVOS, CREDITOS_CERRADOS'\n",
        "    ]\n",
        "})\n",
        "\n",
        "display(variables_drop.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Código de Eliminación de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Drop de variables redundantes/derivadas\n",
        "df = df.drop(columns=[\n",
        "    # Edad - se usa la derivada EDAD_ANOS\n",
        "    'DAYS_BIRTH',\n",
        "    \n",
        "    # Montos base - capturados en ratios\n",
        "    'AMT_CREDIT',\n",
        "    'AMT_INCOME_TOTAL',\n",
        "    'AMT_ANNUITY',\n",
        "    \n",
        "    # Scores individuales - se usa SCORE_PROMEDIO\n",
        "    'EXT_SOURCE_1',\n",
        "    'EXT_SOURCE_2',\n",
        "    'EXT_SOURCE_3',\n",
        "    \n",
        "    # Familia - usada para calcular INGRESO_PER_CAPITA\n",
        "    'CNT_FAM_MEMBERS',\n",
        "    \n",
        "    # Activos - incluidos en NUM_ACTIVOS\n",
        "    'FLAG_OWN_CAR',\n",
        "    'FLAG_OWN_REALTY',\n",
        "    \n",
        "    # Consultas buró total - baja correlación\n",
        "    'TOTAL_CONSULTAS_BURO',\n",
        "    \n",
        "    # Componente de ratio\n",
        "    'MESES_CON_MORA',\n",
        "    \n",
        "    # Variables binarias derivadas\n",
        "    'TIENE_IMPAGOS',\n",
        "    'ES_PRIMER_CREDITO',\n",
        "    \n",
        "    # Créditos buró - baja correlación\n",
        "    'CANTIDAD_CREDITOS_BURO'\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Justificación de la Reducción\n",
        "\n",
        "La reducción de 39 a 24 variables ofrece varias ventajas:\n",
        "\n",
        "1. **Reducción de multicolinealidad**: Eliminamos variables altamente correlacionadas entre sí\n",
        "2. **Simplificación del modelo**: Menos variables facilitan la interpretación\n",
        "3. **Menor riesgo de overfitting**: Modelos más parsimoniosos generalizan mejor\n",
        "4. **Pérdida mínima de AUC**: Solo 0.44% de pérdida en Random Forest (0.7451 → 0.7407)\n",
        "\n",
        "# Regresión Logística\n",
        "\n",
        "## Teoría\n",
        "\n",
        "### Función Sigmoide\n",
        "\n",
        "La regresión logística es un modelo de clasificación que estima la probabilidad de que una observación pertenezca a una clase particular. El modelo utiliza la **función sigmoide** (o logística) para transformar una combinación lineal de las variables predictoras en una probabilidad:\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "$$\n",
        "z = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "z = np.linspace(-10, 10, 200)\n",
        "sigmoid = 1 / (1 + np.exp(-z))\n",
        "\n",
        "ax.plot(z, sigmoid, 'b-', linewidth=2.5, label=r'$\\sigma(z) = \\frac{1}{1 + e^{-z}}$')\n",
        "ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Umbral de decisión (0.5)')\n",
        "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
        "ax.axhline(y=1, color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
        "ax.axvline(x=0, color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
        "\n",
        "ax.fill_between(z, sigmoid, 0.5, where=(sigmoid > 0.5), alpha=0.3, color='red', label='Clase 1 (Default)')\n",
        "ax.fill_between(z, sigmoid, 0.5, where=(sigmoid < 0.5), alpha=0.3, color='blue', label='Clase 0 (No Default)')\n",
        "\n",
        "ax.set_xlabel('z (combinación lineal)', fontsize=12)\n",
        "ax.set_ylabel('P(Y=1|X)', fontsize=12)\n",
        "ax.set_title('Función Sigmoide para Clasificación Binaria', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='center right')\n",
        "ax.grid(alpha=0.3)\n",
        "ax.set_xlim(-10, 10)\n",
        "ax.set_ylim(-0.05, 1.05)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretación de Coeficientes\n",
        "\n",
        "Los coeficientes $\\beta_j$ se interpretan en términos de **odds ratios**:\n",
        "\n",
        "$$\n",
        "\\text{OR}_j = e^{\\beta_j}\n",
        "$$\n",
        "\n",
        "- Si $\\beta_j > 0$: La variable aumenta la probabilidad de default\n",
        "- Si $\\beta_j < 0$: La variable disminuye la probabilidad de default\n",
        "- Si $\\beta_j = 0$: La variable no tiene efecto\n",
        "\n",
        "### Función de Pérdida: Log-Loss (Entropía Cruzada Binaria)\n",
        "\n",
        "Los parámetros se estiman minimizando la **log-loss** (también conocida como entropía cruzada binaria):\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\beta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i) \\right]\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $y_i$ es la etiqueta real (0 o 1)\n",
        "- $\\hat{p}_i = P(Y_i = 1 | X_i)$ es la probabilidad predicha\n",
        "\n",
        "## Parámetros y Entrenamiento\n",
        "\n",
        "### Regularización\n",
        "\n",
        "Para prevenir el overfitting, aplicamos **regularización L2 (Ridge)**:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{reg}(\\beta) = \\mathcal{L}(\\beta) + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
        "$$\n",
        "\n",
        "Tipos de regularización disponibles:\n",
        "\n",
        "| Tipo | Fórmula | Efecto |\n",
        "|------|---------|--------|\n",
        "| **L1 (Lasso)** | $\\lambda \\sum \\|\\beta_j\\|$ | Genera coeficientes exactamente 0 (selección de variables) |\n",
        "| **L2 (Ridge)** | $\\lambda \\sum \\beta_j^2$ | Reduce magnitud de coeficientes (usado en este análisis) |\n",
        "| **Elastic Net** | $\\alpha \\cdot L1 + (1-\\alpha) \\cdot L2$ | Combinación de ambos |\n",
        "\n",
        "### Configuración del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',           # Regularización L2 (Ridge)\n",
        "    C=1.0,                  # Inverso de la fuerza de regularización\n",
        "    solver='lbfgs',         # Algoritmo de optimización\n",
        "    max_iter=1000,          # Máximo de iteraciones\n",
        "    class_weight='balanced', # Balanceo de clases\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validación Cruzada\n",
        "\n",
        "Utilizamos **5-fold cross-validation** para evaluar la estabilidad del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cv_logreg = pd.DataFrame({\n",
        "    'Fold': [1, 2, 3, 4, 5, 'Media'],\n",
        "    'ROC-AUC': [0.7311, 0.7257, 0.7297, 0.7346, 0.7382, 0.7319],\n",
        "    'Std': ['-', '-', '-', '-', '-', '±0.0042']\n",
        "})\n",
        "\n",
        "display(cv_logreg.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "logreg_results = pd.DataFrame({\n",
        "    'Métrica': ['ROC-AUC', 'Average Precision', 'Accuracy', 'Recall (Default)', 'Precision (Default)'],\n",
        "    'Train': [0.7323, 0.2049, 0.6800, 0.66, 0.15],\n",
        "    'Test': [0.7335, 0.2112, 0.6832, 0.66, 0.15],\n",
        "    'Diferencia': [0.0012, 0.0063, 0.0032, 0.00, 0.00]\n",
        "})\n",
        "\n",
        "display(logreg_results.style.hide(axis='index')\n",
        "        .format({'Train': '{:.4f}', 'Test': '{:.4f}', 'Diferencia': '{:+.4f}'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matriz de Confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Datos de la matriz de confusión\n",
        "cm = np.array([[18988, 37550], [1688, 3277]])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "            xticklabels=['No Default', 'Default'],\n",
        "            yticklabels=['No Default', 'Default'],\n",
        "            annot_kws={'size': 14})\n",
        "\n",
        "ax.set_xlabel('Predicción', fontsize=12)\n",
        "ax.set_ylabel('Real', fontsize=12)\n",
        "ax.set_title('Matriz de Confusión - Regresión Logística\\n(Test Set: 61,503 usuarios)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Añadir porcentajes\n",
        "total = cm.sum()\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        pct = cm[i, j] / total * 100\n",
        "        ax.text(j + 0.5, i + 0.75, f'({pct:.1f}%)', ha='center', va='center', fontsize=10, color='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importancia de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "importancia_logreg = pd.DataFrame({\n",
        "    'Variable': ['SCORE_PROMEDIO', 'EDAD_ANOS', 'CREDIT_INCOME_RATIO', 'CREDITOS_ACTIVOS',\n",
        "                 'PCT_MESES_MORA', 'INGRESO_PER_CAPITA', 'TOTAL_DEUDA_ACTUAL', 'NUM_ACTIVOS',\n",
        "                 'PLAZO_PROMEDIO', 'RATIO_PAGO_CUOTA', 'CREDITOS_CERRADOS', 'CNT_CHILDREN',\n",
        "                 'NUM_PRESTAMOS_PREVIOS', 'TOTAL_CREDITO_OTORGADO', 'NAME_EDUCATION_TYPE'],\n",
        "    'Coeficiente': [-1.23, -0.45, 0.32, 0.28, 0.25, -0.22, 0.18, -0.15,\n",
        "                    0.14, 0.12, -0.11, 0.10, 0.09, -0.08, -0.07]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "colors = ['#e74c3c' if c > 0 else '#3498db' for c in importancia_logreg['Coeficiente']]\n",
        "bars = ax.barh(importancia_logreg['Variable'], importancia_logreg['Coeficiente'], \n",
        "               color=colors, edgecolor='black', alpha=0.7)\n",
        "\n",
        "ax.axvline(x=0, color='black', linewidth=1)\n",
        "ax.set_xlabel('Coeficiente (β)', fontsize=12)\n",
        "ax.set_title('Coeficientes de Regresión Logística\\n(Rojo = Aumenta riesgo, Azul = Disminuye riesgo)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, importancia_logreg['Coeficiente']):\n",
        "    ax.text(val + 0.02 if val > 0 else val - 0.02, bar.get_y() + bar.get_height()/2,\n",
        "            f'{val:.2f}', va='center', ha='left' if val > 0 else 'right', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación:**\n",
        "\n",
        "- **SCORE_PROMEDIO** (β = -1.23): El predictor más importante. Un aumento de 1 desviación estándar disminuye el log-odds de default en 1.23\n",
        "- **EDAD_ANOS** (β = -0.45): Mayor edad reduce el riesgo de default\n",
        "- **CREDITOS_ACTIVOS** (β = +0.28): Más créditos activos aumentan el riesgo\n",
        "- **PCT_MESES_MORA** (β = +0.25): Mayor historial de mora aumenta el riesgo\n",
        "\n",
        "# Random Forest\n",
        "\n",
        "## Descripción del Modelo\n",
        "\n",
        "Random Forest es un algoritmo de **ensemble learning** basado en árboles de decisión. El modelo construye múltiples árboles utilizando:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating)**: Cada árbol se entrena con una muestra bootstrap del conjunto de datos\n",
        "2. **Selección aleatoria de features**: En cada split, solo se considera un subconjunto aleatorio de variables\n",
        "\n",
        "Para clasificación, la predicción final se obtiene por **votación mayoritaria**:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\text{mode}\\{\\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_B\\}\n",
        "$$\n",
        "\n",
        "Donde $B$ es el número de árboles.\n",
        "\n",
        "### Importancia de Variables (Gini Importance)\n",
        "\n",
        "La importancia de una variable se mide como la reducción promedio de la impureza de Gini:\n",
        "\n",
        "$$\n",
        "\\text{Gini}(t) = 1 - \\sum_{k=1}^{K} p_{tk}^2\n",
        "$$\n",
        "\n",
        "Donde $p_{tk}$ es la proporción de observaciones de clase $k$ en el nodo $t$.\n",
        "\n",
        "## Hiperparámetros\n",
        "\n",
        "Se entrenaron tres versiones del modelo Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "hp_rf = pd.DataFrame({\n",
        "    'Parámetro': ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', \n",
        "                  'max_features', 'criterion', 'class_weight'],\n",
        "    'RF1 (39 vars)': [100, 15, 10, 5, 'auto', 'gini', 'balanced'],\n",
        "    'RF2 (24 vars)': [100, 15, 10, 5, 'auto', 'gini', 'balanced'],\n",
        "    'RF3 (Optimizado)': [200, 'None', 30, 5, 'sqrt', 'entropy', 'balanced']\n",
        "})\n",
        "\n",
        "display(hp_rf.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "rf_results = pd.DataFrame({\n",
        "    'Métrica': ['ROC-AUC (Test)', 'Average Precision (Test)', 'ROC-AUC (Train)', \n",
        "                'Overfitting (Gap)', 'Recall (Default)', 'Precision (Default)'],\n",
        "    'RF1 (39 vars)': [0.7451, 0.2207, 0.9222, 0.1771, 0.44, 0.21],\n",
        "    'RF2 (24 vars)': [0.7407, 0.2133, 0.9038, 0.1631, 0.46, 0.20],\n",
        "    'RF3 (Optimizado)': [0.7482, 0.2281, 0.9905, 0.2423, 0.24, 0.29]\n",
        "})\n",
        "\n",
        "display(rf_results.style.hide(axis='index')\n",
        "        .format({'RF1 (39 vars)': '{:.4f}', 'RF2 (24 vars)': '{:.4f}', 'RF3 (Optimizado)': '{:.4f}'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Análisis de resultados:**\n",
        "\n",
        "1. **RF1 vs RF2**: Eliminar 15 variables redundantes causa una pérdida mínima de AUC (0.0044), validando nuestra selección de variables\n",
        "2. **RF3 (Optimizado)**: La búsqueda de hiperparámetros mejora el AUC en test (+0.0074) pero aumenta el overfitting\n",
        "3. **Trade-off Recall vs Precision**: RF3 tiene mayor precisión (29% vs 21%) pero menor recall (24% vs 44%)\n",
        "\n",
        "### Importancia de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "importancia_rf = pd.DataFrame({\n",
        "    'Variable': ['SCORE_PROMEDIO', 'EDAD_ANOS', 'CREDIT_INCOME_RATIO', 'RATIO_PAGO_CUOTA',\n",
        "                 'TOTAL_CREDITO_OTORGADO', 'TOTAL_CREDITO_HISTORICO', 'MONTO_PROMEDIO_PREVIO',\n",
        "                 'PLAZO_PROMEDIO', 'TOTAL_DEUDA_ACTUAL', 'INGRESO_PER_CAPITA',\n",
        "                 'CREDITOS_CERRADOS', 'RATIO_PAGO_MINIMO_TC', 'NAME_EDUCATION_TYPE',\n",
        "                 'NUM_PRESTAMOS_PREVIOS', 'CREDITOS_ACTIVOS'],\n",
        "    'Importancia': [0.321, 0.082, 0.055, 0.053, 0.051, 0.048, 0.047, 0.046,\n",
        "                    0.040, 0.038, 0.031, 0.027, 0.025, 0.025, 0.023]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "bars = ax.barh(importancia_rf['Variable'], importancia_rf['Importancia'], \n",
        "               color='forestgreen', alpha=0.7, edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Importancia (Reducción promedio de Gini)')\n",
        "ax.set_title('Importancia de Variables - Random Forest\\n(Capacidad para separar clases)', fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, importancia_rf['Importancia']):\n",
        "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
        "            va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hallazgo clave**: `SCORE_PROMEDIO` domina la importancia con 32.1%, más del triple que la segunda variable más importante. Esto confirma que los scores externos son el factor más determinante para predecir el riesgo de impago.\n",
        "\n",
        "# XGBoost\n",
        "\n",
        "## Descripción del Modelo\n",
        "\n",
        "**XGBoost** (Extreme Gradient Boosting) es un algoritmo de **boosting** que construye árboles de decisión de manera secuencial. A diferencia de Random Forest que construye árboles en paralelo, XGBoost:\n",
        "\n",
        "1. **Entrena árboles secuencialmente**: Cada árbol corrige los errores del anterior\n",
        "2. **Utiliza gradient boosting**: Optimiza una función de pérdida usando gradiente descendente\n",
        "3. **Incluye regularización**: Penaliza la complejidad del modelo para prevenir overfitting\n",
        "\n",
        "### Mecanismo de Boosting\n",
        "\n",
        "El modelo final es una suma ponderada de árboles:\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\sum_{k=1}^{K} f_k(x_i)\n",
        "$$\n",
        "\n",
        "Donde cada árbol $f_k$ se entrena para minimizar:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}^{(k)} = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i^{(k-1)} + f_k(x_i)) + \\Omega(f_k)\n",
        "$$\n",
        "\n",
        "La regularización $\\Omega(f_k)$ incluye:\n",
        "- **L1 (alpha)**: Regularización de pesos\n",
        "- **L2 (lambda)**: Regularización de scores de hojas\n",
        "- **gamma**: Penalización por complejidad del árbol\n",
        "\n",
        "### Learning Rate (η)\n",
        "\n",
        "El learning rate controla la contribución de cada árbol:\n",
        "\n",
        "$$\n",
        "\\hat{y}_i^{(k)} = \\hat{y}_i^{(k-1)} + \\eta \\cdot f_k(x_i)\n",
        "$$\n",
        "\n",
        "- **η pequeño** (0.01-0.1): Aprendizaje más lento pero mejor generalización\n",
        "- **η grande** (0.1-0.3): Aprendizaje más rápido pero riesgo de overfitting\n",
        "\n",
        "## Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "hp_xgb = pd.DataFrame({\n",
        "    'Parámetro': ['n_estimators', 'max_depth', 'learning_rate', 'min_child_weight',\n",
        "                  'subsample', 'colsample_bytree', 'scale_pos_weight', 'eval_metric'],\n",
        "    'XGB1 (39 vars)': [100, 6, 0.1, 5, 0.8, 0.8, 11.38, 'auc'],\n",
        "    'XGB2 (24 vars)': [100, 6, 0.1, 5, 0.8, 0.8, 11.38, 'auc'],\n",
        "    'Descripción': ['Número de árboles', 'Profundidad máxima por árbol', \n",
        "                    'Tasa de aprendizaje', 'Suma mínima de pesos en hoja',\n",
        "                    'Fracción de muestras por árbol', 'Fracción de features por árbol',\n",
        "                    'Ratio para balanceo de clases', 'Métrica de evaluación']\n",
        "})\n",
        "\n",
        "display(hp_xgb.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "xgb_results = pd.DataFrame({\n",
        "    'Métrica': ['ROC-AUC (Test)', 'Average Precision (Test)', 'ROC-AUC (Train)', \n",
        "                'Overfitting (Gap)', 'Recall (Default)', 'Precision (Default)'],\n",
        "    'XGB1 (39 vars)': [0.7612, 0.2389, 0.7845, 0.0233, 0.52, 0.23],\n",
        "    'XGB2 (24 vars)': [0.7589, 0.2341, 0.7798, 0.0209, 0.51, 0.22]\n",
        "})\n",
        "\n",
        "display(xgb_results.style.hide(axis='index')\n",
        "        .format({'XGB1 (39 vars)': '{:.4f}', 'XGB2 (24 vars)': '{:.4f}'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importancia de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "importancia_xgb = pd.DataFrame({\n",
        "    'Variable': ['SCORE_PROMEDIO', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'EDAD_ANOS',\n",
        "                 'EXT_SOURCE_1', 'RATIO_PAGO_CUOTA', 'AMT_ANNUITY', 'AMT_CREDIT',\n",
        "                 'CREDIT_INCOME_RATIO', 'PLAZO_PROMEDIO', 'TOTAL_CREDITO_OTORGADO',\n",
        "                 'TOTAL_CREDITO_HISTORICO', 'MONTO_PROMEDIO_PREVIO', 'TOTAL_DEUDA_ACTUAL',\n",
        "                 'INGRESO_PER_CAPITA'],\n",
        "    'Importancia': [0.183, 0.095, 0.094, 0.043, 0.038, 0.036, 0.036, 0.035,\n",
        "                    0.034, 0.031, 0.031, 0.030, 0.030, 0.024, 0.023]\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "bars = ax.barh(importancia_xgb['Variable'], importancia_xgb['Importancia'], \n",
        "               color='#2E86AB', alpha=0.7, edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Importancia (Gain)')\n",
        "ax.set_title('Importancia de Variables - XGBoost\\n(Ganancia promedio en splits)', fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for bar, val in zip(bars, importancia_xgb['Importancia']):\n",
        "    ax.text(val + 0.003, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
        "            va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de Modelos\n",
        "\n",
        "## Métricas Globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "comparacion_final = pd.DataFrame({\n",
        "    'Métrica': ['ROC-AUC (Test)', 'Average Precision', 'Recall (Default)', \n",
        "                'Precision (Default)', 'Overfitting (Gap)', 'Interpretabilidad', \n",
        "                'Tiempo de entrenamiento'],\n",
        "    'Regresión Logística': ['0.7335', '0.2112', '66%', '15%', '0.0012', 'Alta', 'Rápido'],\n",
        "    'Random Forest': ['0.7482', '0.2281', '24-46%', '20-29%', '0.1631-0.2423', 'Media', 'Moderado'],\n",
        "    'XGBoost': ['0.7612', '0.2389', '51-52%', '22-23%', '0.0209-0.0233', 'Baja', 'Moderado'],\n",
        "    'Mejor': ['XGBoost', 'XGBoost', 'LogReg', 'RF', 'LogReg', 'LogReg', 'LogReg']\n",
        "})\n",
        "\n",
        "display(comparacion_final.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Curvas ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Datos simulados para las curvas (basados en los AUCs reales)\n",
        "fpr_lr = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "tpr_lr = np.array([0, 0.35, 0.50, 0.60, 0.68, 0.75, 0.82, 0.88, 0.93, 0.97, 1.0])\n",
        "\n",
        "fpr_rf = np.array([0, 0.08, 0.16, 0.25, 0.35, 0.45, 0.55, 0.65, 0.78, 0.90, 1.0])\n",
        "tpr_rf = np.array([0, 0.38, 0.53, 0.64, 0.72, 0.79, 0.85, 0.90, 0.95, 0.98, 1.0])\n",
        "\n",
        "fpr_xgb = np.array([0, 0.06, 0.14, 0.22, 0.32, 0.42, 0.52, 0.63, 0.76, 0.89, 1.0])\n",
        "tpr_xgb = np.array([0, 0.42, 0.58, 0.68, 0.76, 0.82, 0.87, 0.92, 0.96, 0.99, 1.0])\n",
        "\n",
        "# ROC Curves\n",
        "axes[0].plot(fpr_lr, tpr_lr, 'b-', linewidth=2, label='Regresión Logística (AUC=0.73)')\n",
        "axes[0].plot(fpr_rf, tpr_rf, 'g-', linewidth=2, label='Random Forest (AUC=0.75)')\n",
        "axes[0].plot(fpr_xgb, tpr_xgb, 'r-', linewidth=2, label='XGBoost (AUC=0.76)')\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Aleatorio')\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('Curvas ROC')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Precision-Recall Curves\n",
        "recall_lr = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "precision_lr = np.array([1.0, 0.45, 0.35, 0.28, 0.22, 0.18, 0.15, 0.12, 0.10, 0.09, 0.08])\n",
        "\n",
        "recall_rf = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "precision_rf = np.array([1.0, 0.50, 0.40, 0.32, 0.26, 0.22, 0.18, 0.15, 0.12, 0.10, 0.08])\n",
        "\n",
        "recall_xgb = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "precision_xgb = np.array([1.0, 0.55, 0.44, 0.36, 0.30, 0.25, 0.20, 0.16, 0.13, 0.11, 0.08])\n",
        "\n",
        "axes[1].plot(recall_lr, precision_lr, 'b-', linewidth=2, label='Regresión Logística (AP=0.21)')\n",
        "axes[1].plot(recall_rf, precision_rf, 'g-', linewidth=2, label='Random Forest (AP=0.23)')\n",
        "axes[1].plot(recall_xgb, precision_xgb, 'r-', linewidth=2, label='XGBoost (AP=0.24)')\n",
        "axes[1].axhline(y=0.08, color='gray', linestyle='--', label='Baseline (8%)')\n",
        "axes[1].set_xlabel('Recall')\n",
        "axes[1].set_ylabel('Precision')\n",
        "axes[1].set_title('Curvas Precision-Recall')\n",
        "axes[1].legend(loc='upper right')\n",
        "axes[1].grid(alpha=0.3)\n",
        "axes[1].set_xlim([0, 1])\n",
        "axes[1].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparación de Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Top 10 variables más importantes por modelo\n",
        "top_vars = ['SCORE_PROMEDIO', 'EDAD_ANOS', 'CREDIT_INCOME_RATIO', 'RATIO_PAGO_CUOTA',\n",
        "            'TOTAL_CREDITO_OTORGADO', 'PLAZO_PROMEDIO', 'TOTAL_DEUDA_ACTUAL',\n",
        "            'INGRESO_PER_CAPITA', 'CREDITOS_ACTIVOS', 'PCT_MESES_MORA']\n",
        "\n",
        "imp_logreg = [1.0, 0.37, 0.26, 0.10, 0.07, 0.11, 0.15, 0.18, 0.23, 0.20]\n",
        "imp_rf = [1.0, 0.26, 0.17, 0.17, 0.16, 0.14, 0.12, 0.12, 0.07, 0.04]\n",
        "imp_xgb = [1.0, 0.24, 0.19, 0.20, 0.17, 0.17, 0.13, 0.13, 0.08, 0.05]\n",
        "\n",
        "x = np.arange(len(top_vars))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "bars1 = ax.bar(x - width, imp_logreg, width, label='Regresión Logística', color='steelblue', alpha=0.8)\n",
        "bars2 = ax.bar(x, imp_rf, width, label='Random Forest', color='forestgreen', alpha=0.8)\n",
        "bars3 = ax.bar(x + width, imp_xgb, width, label='XGBoost', color='#E94F37', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Variable', fontsize=12)\n",
        "ax.set_ylabel('Importancia Relativa (normalizada)', fontsize=12)\n",
        "ax.set_title('Comparación de Importancia de Variables entre Modelos', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(top_vars, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matrices de Confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "# Datos de matrices de confusión\n",
        "cms = [\n",
        "    np.array([[18988, 37550], [1688, 3277]]),  # Logistic Regression\n",
        "    np.array([[48497, 8041], [2777, 2188]]),   # Random Forest\n",
        "    np.array([[45123, 11415], [2384, 2581]])   # XGBoost\n",
        "]\n",
        "titles = ['Regresión Logística', 'Random Forest', 'XGBoost']\n",
        "colors = ['Blues', 'Greens', 'Reds']\n",
        "\n",
        "for ax, cm, title, cmap in zip(axes, cms, titles, colors):\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=ax,\n",
        "                xticklabels=['No Default', 'Default'],\n",
        "                yticklabels=['No Default', 'Default'],\n",
        "                annot_kws={'size': 12})\n",
        "    ax.set_xlabel('Predicción')\n",
        "    ax.set_ylabel('Real')\n",
        "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusión General\n",
        "\n",
        "## Hallazgos Principales\n",
        "\n",
        "### 1. El Score Crediticio es el Predictor Dominante\n",
        "\n",
        "En los tres modelos, `SCORE_PROMEDIO` emerge como la variable más importante:\n",
        "- **Regresión Logística**: Coeficiente más alto (β = -1.23)\n",
        "- **Random Forest**: 32.1% de la importancia total\n",
        "- **XGBoost**: 18.3% de la importancia (Gain)\n",
        "\n",
        "Esto confirma que los scores de fuentes externas capturan información valiosa sobre el riesgo crediticio.\n",
        "\n",
        "### 2. XGBoost Ofrece el Mejor Rendimiento\n",
        "\n",
        "| Modelo | ROC-AUC | Average Precision | Overfitting |\n",
        "|--------|---------|-------------------|-------------|\n",
        "| Regresión Logística | 0.7335 | 0.2112 | Bajo (0.12%) |\n",
        "| Random Forest | 0.7482 | 0.2281 | Alto (16-24%) |\n",
        "| **XGBoost** | **0.7612** | **0.2389** | **Bajo (2%)** |\n",
        "\n",
        "### 3. Trade-off entre Interpretabilidad y Rendimiento\n",
        "\n",
        "- **Regresión Logística**: Mayor interpretabilidad (coeficientes directos), menor rendimiento\n",
        "- **XGBoost**: Mejor rendimiento, pero menor interpretabilidad\n",
        "- **Random Forest**: Balance intermedio, pero con mayor overfitting\n",
        "\n",
        "## Ventajas y Desventajas de Cada Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "comparacion = pd.DataFrame({\n",
        "    'Modelo': ['Regresión Logística', 'Random Forest', 'XGBoost'],\n",
        "    'Ventajas': [\n",
        "        '• Alta interpretabilidad\\n• Sin overfitting\\n• Rápido entrenamiento\\n• Coeficientes interpretables',\n",
        "        '• Captura interacciones\\n• Robusto a outliers\\n• Feature importance\\n• No requiere normalización',\n",
        "        '• Mejor AUC\\n• Bajo overfitting\\n• Maneja desbalance\\n• Regularización integrada'\n",
        "    ],\n",
        "    'Desventajas': [\n",
        "        '• Asume linealidad\\n• Menor AUC\\n• No captura interacciones',\n",
        "        '• Alto overfitting\\n• Caja negra\\n• Mayor tiempo de entrenamiento',\n",
        "        '• Caja negra\\n• Requiere tuning\\n• Mayor complejidad computacional'\n",
        "    ]\n",
        "})\n",
        "\n",
        "display(comparacion.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recomendación Final\n",
        "\n",
        "### Para Producción\n",
        "\n",
        "Recomendamos implementar **XGBoost** como modelo principal por:\n",
        "\n",
        "1. **Mejor rendimiento predictivo** (AUC = 0.76)\n",
        "2. **Buen balance recall-precision** (51% recall, 23% precision)\n",
        "3. **Bajo overfitting** (gap < 3%)\n",
        "4. **Robustez ante desbalance de clases**\n",
        "\n",
        "### Para Monitoreo\n",
        "\n",
        "- Establecer un umbral de probabilidad de **0.3** para maximizar el recall\n",
        "- Implementar **alertas para scores > 0.5** como alto riesgo\n",
        "- Monitorear la distribución de probabilidades para detectar drift\n",
        "\n",
        "### Para Mejora Futura\n",
        "\n",
        "1. **Investigar el contenido de los scores externos** (EXT_SOURCE_1/2/3)\n",
        "2. **Incorporar datos dinámicos** de comportamiento de pago\n",
        "3. **Implementar SHAP values** para explicabilidad del modelo XGBoost\n",
        "4. **Desarrollar modelo de scoring dinámico** que actualice predicciones con datos de comportamiento\n",
        "5. **Análisis de fairness** para asegurar que el modelo no discrimine por características protegidas\n",
        "\n",
        "## Validación de Hipótesis\n",
        "\n",
        "| Hipótesis | Resultado | Evidencia |\n",
        "|-----------|-----------|----------|\n",
        "| Menor score crediticio → Mayor riesgo | ✓ Confirmada | Correlación más fuerte (-0.22), variable #1 en todos los modelos |\n",
        "| Menor edad → Mayor riesgo | ✓ Confirmada | Correlación -0.078, diferencia significativa en perfiles |\n",
        "| Mayor historial de mora → Mayor riesgo | ✓ Confirmada | PCT_MESES_MORA +73% en defaults |\n",
        "| Más créditos activos → Mayor riesgo | ✓ Confirmada | Correlación +0.044, coeficiente positivo en LR |\n",
        "| Menos activos → Mayor riesgo | ✓ Parcialmente | NUM_ACTIVOS -4.7% en defaults, efecto moderado |\n",
        "\n",
        "# Referencias\n",
        "\n",
        "1. Home Credit Group. (2018). *Home Credit Default Risk*. Kaggle Competition. https://www.kaggle.com/competitions/home-credit-default-risk\n",
        "\n",
        "2. Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32.\n",
        "\n",
        "3. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. *Proceedings of the 22nd ACM SIGKDD*.\n",
        "\n",
        "4. Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). *Applied Logistic Regression* (3rd ed.). Wiley.\n",
        "\n",
        "5. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). *An Introduction to Statistical Learning* (2nd ed.). Springer.\n",
        "\n",
        "6. Battagliola, M. L. (2025). *Guía para la Elaboración del Proyecto Final*. ITAM - Estadística Aplicada III.\n",
        "\n",
        "# Anexos\n",
        "\n",
        "## A. Diccionario de Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "diccionario = pd.DataFrame({\n",
        "    'Variable': ['TARGET', 'SCORE_PROMEDIO', 'EDAD_ANOS', 'CREDIT_INCOME_RATIO', \n",
        "                 'INGRESO_PER_CAPITA', 'NUM_ACTIVOS', 'CREDITOS_ACTIVOS', 'CREDITOS_CERRADOS',\n",
        "                 'PCT_MESES_MORA', 'CREDITOS_CON_IMPAGO', 'TOTAL_DEUDA_ACTUAL',\n",
        "                 'TOTAL_CREDITO_OTORGADO', 'PLAZO_PROMEDIO', 'RATIO_PAGO_CUOTA',\n",
        "                 'NAME_FAMILY_STATUS', 'CODE_GENDER', 'NAME_EDUCATION_TYPE'],\n",
        "    'Descripción': ['Variable objetivo (1=Default, 0=No Default)', \n",
        "                    'Promedio de scores externos EXT_SOURCE_1/2/3',\n",
        "                    'Edad del solicitante en años',\n",
        "                    'Ratio crédito solicitado / ingreso total',\n",
        "                    'Ingreso total / miembros de familia',\n",
        "                    'Suma de activos (auto + inmueble)',\n",
        "                    'Número de créditos activos en buró',\n",
        "                    'Número de créditos cerrados en buró',\n",
        "                    'Porcentaje histórico de meses con mora',\n",
        "                    'Número de créditos con historial de impago',\n",
        "                    'Deuda total vigente',\n",
        "                    'Suma histórica de créditos otorgados',\n",
        "                    'Plazo promedio de créditos previos',\n",
        "                    'Ratio pago realizado / cuota programada',\n",
        "                    'Estado civil',\n",
        "                    'Género',\n",
        "                    'Nivel educativo'],\n",
        "    'Tipo': ['Binaria', 'Continua [0,1]', 'Continua', 'Continua',\n",
        "             'Continua', 'Discreta [0,2]', 'Discreta', 'Discreta',\n",
        "             'Continua [0,100]', 'Discreta', 'Continua',\n",
        "             'Continua', 'Continua', 'Continua',\n",
        "             'Categórica', 'Categórica', 'Categórica']\n",
        "})\n",
        "\n",
        "display(diccionario.style.hide(axis='index'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Código Fuente\n",
        "\n",
        "El código completo de este análisis está disponible en los siguientes notebooks:\n",
        "\n",
        "- `src/eda/eda.ipynb`: Análisis exploratorio de datos\n",
        "- `src/eda/variables.ipynb`: Generación de variables y Regresión Logística\n",
        "- `src/random_forest/random_forest.ipynb`: Modelos Random Forest\n",
        "- `src/xgboost/jp-xgboost.ipynb`: Modelos XGBoost"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aplicada",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
